<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Inferential statistics II.</title>
    <meta charset="utf-8" />
    <meta name="author" content="Marcell Granát" />
    <meta name="date" content="2022-01-01" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
    <link href="libs/tile-view/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view/tile-view.js"></script>
  </head>
  <body>
    <textarea id="source">
class: center, middle, title-slide

.title[
# Inferential statistics II.
]
.subtitle[
## <img src="mnb_intezet.png" style="width:30.0%" />
Big Data and Data Visualisation
]
.author[
### Marcell Granát
]
.institute[
### Central Bank of Hungary &amp; .blue[John von Neumann University]
]
.date[
### 2022
]

---


&lt;style type="text/css"&gt;
.red { color: red; }
.blue { color: #378C95; }
strong { color: red; }
a { color: #378C95; font-weight: bold; }
.remark-inline-code { font-weight: 900; background-color: #a7d5e7; }
.caption { color: #378C95; font-style: italic; text-align: center; }

.content-box { 
box-sizing: content-box;
background-color: #378C95;
/* Total width: 160px + (2 * 20px) + (2 * 8px) = 216px
Total height: 80px + (2 * 20px) + (2 * 8px) = 136px
Content box width: 160px
Content box height: 80px */
}

.content-box-green {
background-color: #d9edc2;
}

.content-box-red {
background-color: #f9dbdb;
}

.fullprice {
text-decoration: line-through;
}
&lt;/style&gt;





# Today's .blue[Agenda]

### Session (1-2) - Inferential statistics II.

1. IID mean estimation II.

2. Concepts of hypothesis testing

3. Hypothesis testing in R

4. One-sample testing

5. Two-sample tests

6. Multiple-sample tests

---

class: inverse, middle, center

# IID mean estimation II.

---
## An illustrative example

Let's continue where we stopped!

--

A machine extracts coffee into the bottles. It is known from previous data recordings that the weight loaded by the machine is a random variable with a normal distribution, with a standard deviation of 1.5 g.
The weight (g) of the coffee granules in the bottles in the 16-element sample taken to check the accuracy of the machine:

55, 54, 54, 56, 57, 56, 55, 57, 54, 56, 55, 54, 57, 54, 56, 50.

#### Let!s calculate the 95% confidence interval to the expected weight.

---
## An illustrative example

Let's continue where we stopped!

A machine extracts coffee into the bottles. It is known from previous data recordings that the weight loaded by the machine is a random variable with a normal distribution, **with a standard deviation of 1.5 g.**
The weight (g) of the coffee granules in the bottles in the 16-element sample taken to check the accuracy of the machine:

55, 54, 54, 56, 57, 56, 55, 57, 54, 56, 55, 54, 57, 54, 56, 50.

#### Let!s calculate the 95% confidence interval to the expected weight.

--

.blue[Why did we need to know the variance in the population?]

--

#### Let!s calculate the 95% confidence interval to the expected weight assuming that we have no prior information about the standard deviation.

In this case, there is another uncertainty factor in the calculation. We also **estimate the standard deviation** for drawing the distribution.

---

## Mean estimation with an unknown standard deviation

Mean point estimation:

$$
\bar{x}=\frac{1}{n} \sum_{i=1}^n x_i
$$

SD estimation:

$$
s^2=\frac{1}{n-1} \sum_{i=1}^n\left(x_i-\bar{x}\right)^2
$$
Then the **Student T-distribution** can be derived as:

$$
t(n-1)=\frac{\bar{x}-\mu}{\sigma / \sqrt{n}},
$$

where `\(\mu\)` denotes the population mean and `\(\sigma\)` denotes the standard deviation of the population.

---

## The Student T-distribution

$$
t(n-1)=\frac{\bar{x}-\mu}{S / \sqrt{n}},
$$

where `\(n-1\)` is called as the degree of freedom.

--

&lt;img src="inferential-statistics2_files/figure-html/unnamed-chunk-2-1.png" width="700px" height="400px" style="display: block; margin: auto;" /&gt;

---

## The Student T-distribution

$$
t(n-1)=\frac{\bar{x}-\mu}{S / \sqrt{n}},
$$

where `\(n-1\)` is called the degree of freedom.

&lt;img src="inferential-statistics2_files/figure-html/unnamed-chunk-3-1.png" width="700px" height="400px" style="display: block; margin: auto;" /&gt;

---

## An illustrative example

#### Let!s calculate the 95% confidence interval to the expected weight assuming that we have no prior information about the standard deviation.

--

Confidence interval:

`$$\bar{x} \pm t_{97.5}(n-1)\frac{s}{\sqrt{n}}$$`

--


```r
y &lt;-c(55, 54, 54, 56, 57, 56, 55, 57, 54, 56, 55, 54, 57, 54, 56, 50)
mean(y)
```

```
## [1] 55
```


```r
qt(.975, df = length(y) - 1)
```

```
## [1] 2.13145
```


```r
sd(y) # divided by n - 1 !!!
```

```
## [1] 1.75119
```

---

## An illustrative example

#### Let!s calculate the 95% confidence interval to expected weight assuming that we have no prior information about the standard deviation.

Confidence interval:

`$$\bar{x} \pm t_{97.5}(n-1)\frac{s}{\sqrt{n}} = 55 \pm 2.1315\frac{1.7512}{\sqrt{16}} = (54.07, 55.93)$$`

--


```r
y &lt;-c(55, 54, 54, 56, 57, 56, 55, 57, 54, 56, 55, 54, 57, 54, 56, 50)
mean(y)
```

```
## [1] 55
```


```r
qt(.975, df = length(y) - 1)
```

```
## [1] 2.13145
```


```r
sd(y) # divided by n - 1 !!!
```

```
## [1] 1.75119
```

---


## The probability function

The daily payment amount in a bank follows a normal distribution, with parameters `\(\mu\)`=HUF 3.6 million, `\(\sigma\)`=HUF 0.9 million.

#### What is the probability that on a given day the payment amount is ...

--

##### 1. below HUF 3 million?


```r
pnorm(q = 3, mean = 3.6, sd = .9)
```

```
## [1] 0.2524925
```

&lt;img src="inferential-statistics2_files/figure-html/unnamed-chunk-11-1.png" width="700px" height="270px" style="display: block; margin: auto;" /&gt;


---

## The probability function

The daily payment amount in a bank follows a normal distribution, with parameters `\(\mu\)`=HUF 3.6 million, `\(\sigma\)`=HUF 0.9 million.

#### What is the probability that on a given day the payment amount is ...

##### 1. below HUF 3 million?


```r
pnorm(q = 3, mean = 3.6, sd = .9)
```

```
## [1] 0.2524925
```

--

##### 2. above HUF 5 million?

--


```r
1 - pnorm(q = 5, mean = 3.6, sd = .9)
```

```
## [1] 0.05990691
```

---

## The probability function

The daily payment amount in a bank follows a normal distribution, with parameters `\(\mu\)`=HUF 3.6 million, `\(\sigma\)`=HUF 0.9 million.

#### What is the probability that on a given day the payment amount is ...

##### 3. between HUF 2.7 and 4.5 million?

--


```r
pnorm(q = 4.5, mean = 3.6, sd = .9) -
  pnorm(q = 2.7, mean = 3.6, sd = .9)
```

```
## [1] 0.6826895
```

---

## The probability function

The daily payment amount in a bank follows a normal distribution, with parameters `\(\mu\)`=HUF 3.6 million, `\(\sigma\)`=HUF 0.9 million.

#### How much money should be kept in the bank if we want to ensure that payments can be performed with a 95% probability?

--


```r
qnorm(p = .95, mean = 3.6, sd = .9)
```

```
## [1] 5.080368
```

--

&lt;img src="inferential-statistics2_files/figure-html/unnamed-chunk-16-1.png" width="700px" height="270px" style="display: block; margin: auto;" /&gt;

---

class: inverse, middle, center

# Concepts of hypothesis testing

---

## Concepts of hypothesis testing

&gt; Hypothesis test is a procedure that between the sample value and population value hypothesized is real or due to chance variation.

--

- The bank claims that the average daily payment is HUF 45 million, with a standard deviation of HUF 2 million.

--

- Yesterday it was HUF 42 million. Do you still believe to the bank?

--

- During a year-long observation, he finds that the average was only HUF 40 million. Do you still believe the statement?

???

Source: Maddala &amp; Lahiri

---

## Concepts of hypothesis testing

Steps of hypothesis testing:

1. Set two disjunct hypotheses (only one can be true at once)

--

2. Derive a test statistics **based on the sample**

3. Make a decision about the .blue[null hypothesis]

---

## How to set the .blue[hypothesis]?

- The hypothesis we are testing is called the null hypothesis and is often denoted by **H0**.

- The alternative hypothesis is denoted by **H1**.

--

For instance,

`$$H_0: \: \mu \ge 45 \: \text{against} \: H_1: \: \mu &lt; 45$$`

---

## How to calculate the .blue[test statistics]?

&gt; The test statistic is a **number** calculated from a statistical test of a hypothesis. It shows **how closely your observed data match the distribution expected under the null hypothesis** of that statistical test.

--

Back to our example. Our sample (suppose that the s.d. is known):

`$$\bar{x} = 44 \:\:\:\:\:\: \:\:\:\:\:\: n =365$$`

--

`$$z = \frac{\bar{x} - \theta}{\sigma/\sqrt{n}} =  \frac{44-45}{2/\sqrt{365}}=-9.5525$$`

---

## How to calculate the .blue[test statistics]?

`$$z = \frac{44-45}{2/\sqrt{365}}=-9.5525$$`


```r
pnorm(q = -9.5525, mean = 0, sd = 1)
```

```
## [1] 6.330181e-22
```

```r
pnorm(q = 44, mean = 45, sd = 2 / (365^.5))
```

```
## [1] 6.331001e-22
```

--

&gt; ... shows **how closely your observed data match the distribution expected under the null hypothesis**

If the population follows truly a distribution with HUF 45 million average and HUF 2 million standard deviation, then the probability of getting a sample with HUF 44 million average or less equals .blue[6.331001e-22] (approximately zero).


???

source: https://www.scribbr.com/statistics/test-statistic/

---

### An illustrative example

`rnorm`: random number generation for the normal distribution 





```r
mu &lt;- 0
s &lt;- 1
n &lt;- 10
random_values &lt;- rnorm(n = n, mean = mu, sd = s)

random_values
```

```
##  [1] -0.56047565 -0.23017749  1.55870831  0.07050839  0.12928774  1.71506499
##  [7]  0.46091621 -1.26506123 -0.68685285 -0.44566197
```

```r
multiplier &lt;- 1

random_values &lt; mu - s * 1
```

```
##  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE
```

```r
random_values &gt; mu + s * 1
```

```
##  [1] FALSE FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE
```


---

### An illustrative example


```r
r_interval &lt;- function(mu = 0, s = 1, n = 10, multiplier = 1) {
  
  random_values &lt;- rnorm(n = n, mean = mu, sd = s)
  
  out_interval &lt;- (random_values &lt; mu - s * multiplier) | # above or below
    (random_values &gt; mu + s * multiplier)
  
  1 - sum(out_interval) / n # value to return
}
```

---

### An illustrative example


```r
r_interval(mu = 0, s = 1, n = 10, multiplier = 1)
```

```
## [1] 0.7
```

```r
r_interval(mu = 0, s = 1, n = 10, multiplier = 1)
```

```
## [1] 0.5
```

```r
r_interval(mu = 0, s = 1, n = 10, multiplier = 1)
```

```
## [1] 1
```

```r
r_interval(mu = 0, s = 1, n = 10, multiplier = 1)
```

```
## [1] 0.6
```

--


```r
r_interval(mu = 0, s = 1, n = 1000000, multiplier = 1)
```

```
*## [1] 0.682549
```

---

### An illustrative example

The same result is always obtained in the case of a normal distribution, regardless of the mean and standard deviation.


```r
r_interval(mu = 0, s = 1, n = 1000000, multiplier = 1)
```

```
## [1] 0.683012
```

```r
r_interval(mu = 1, s = 1, n = 1000000, multiplier = 1)
```

```
## [1] 0.682857
```

```r
r_interval(mu = 3, s = 5, n = 1000000, multiplier = 1)
```

```
## [1] 0.682129
```

```r
r_interval(mu = 100, s = 15, n = 1000000, multiplier = 1)
```

```
## [1] 0.683011
```

```r
r_interval(mu = -20, s = 40, n = 1000000, multiplier = 1)
```

```
## [1] 0.682221
```

---

### An illustrative example


```r
r_interval(mu = 0, s = 1, n = 1000000, multiplier = 1)
```

```
## [1] 0.682786
```

```r
r_interval(mu = 1, s = 1, n = 1000000, multiplier = 2)
```

```
## [1] 0.954777
```

```r
r_interval(mu = 3, s = 5, n = 1000000, multiplier = 3)
```

```
## [1] 0.997357
```



```r
r_interval(mu = 100, s = 15, n = 1000000, multiplier = 1.95)
```

```
## [1] 0.948799
```

```r
r_interval(mu = -20, s = 40, n = 1000000, multiplier = 1.65)
```

```
## [1] 0.90077
```

---

### An illustrative example

- Even if HUF 44 million does not sound like a huge difference, if the s.d. in the sample equals 2, then the s.d. of the sample averages is 2 / 365^.5 = 0.1046848

- .1 \* 3 would also be a highly significant difference to not believe that the population mean is 45

- In general, the procedure is to assign a specific boundary (critical value) or boundaries, from which if the value of the test statistic falls further, then I reject the null hypothesis.

- Let's say that I want to reject if the probability of getting a sample average with that value or lower should be .blue[5%]. This is the **significance level**.

--                                                                    


```r
qnorm(.05)
```

```
## [1] -1.644854
```

---

## How to set the .blue[hypothesis]?

#### Alternative: **less** (significance level (alpha) = 5%)

.pull-left[

`$$H_0: \: \mu \ge 45 \: \text{against} \: H_1: \: \mu &lt; 45$$`
]

.pull-right[

```r
qnorm(.05)
```

```
## [1] -1.644854
```

]

&lt;img src="inferential-statistics2_files/figure-html/unnamed-chunk-28-1.png" width="700px" height="350px" style="display: block; margin: auto;" /&gt;

---

## How to set the .blue[hypothesis]?

#### Alternative: **greater** (significance level (alpha) = 5%)

.pull-left[

`$$H_0: \: \mu \leq 45 \: \text{against} \: H_1: \: \mu &gt; 45$$`
]

.pull-right[

```r
qnorm(.95)
```

```
## [1] 1.644854
```

]

&lt;img src="inferential-statistics2_files/figure-html/unnamed-chunk-30-1.png" width="700px" height="350px" style="display: block; margin: auto;" /&gt;

---

## How to set the .blue[hypothesis]?

#### Alternative: **two sided** (significance level (alpha) = 5%)

.pull-left[

`$$H_0: \: \mu = 45 \: \text{against} \: H_1: \: \mu \neq 45$$`
]

.pull-right[

```r
qnorm(c(.025, .975))
```

```
## [1] -1.959964  1.959964
```

]

&lt;img src="inferential-statistics2_files/figure-html/unnamed-chunk-32-1.png" width="700px" height="350px" style="display: block; margin: auto;" /&gt;

---

## Type I &amp; type II errors

- If the null hypothesis is true, we take a random sample, and then the probability to reject incorrectly the H0 is alpha.

  - We call this Type I error

--

- What if the H0 is false in the reality?

Let's assume the following hypothesis:

`$$H_0: \mu = 250 \:\:\:H_1: \mu \neq 250$$`

- But we "know" that the real average is at 254!

`$$S = 4, \:\:\:n = 10$$`

---

## Type I &amp; type II errors



&lt;img src="inferential-statistics2_files/figure-html/unnamed-chunk-34-1.png" width="700px" height="450px" style="display: block; margin: auto;" /&gt;

---

## Type I &amp; type II errors

With a given number of sample size, the probability of committing a type II error is smaller...

1. the higher the alpha significance level we choose.

2. the closer the hypothesis H0 is to the alternative hypothesis H1.

3. the higher the confidence level of the test.

4. the closer the actual value of the examined parameter is to the value specified in the H0 hypothesis.

---

## Type I &amp; type II errors

&lt;img src="inferential-statistics2_files/figure-html/unnamed-chunk-35-.gif" width="700px" height="450px" style="display: block; margin: auto;" /&gt;

---

## Type I &amp; type II errors

&lt;img src="inferential-statistics2_files/figure-html/unnamed-chunk-36-.gif" width="700px" height="450px" style="display: block; margin: auto;" /&gt;

---

## Type I &amp; type II errors

&lt;img src="inferential-statistics2_files/figure-html/unnamed-chunk-37-.gif" width="700px" height="450px" style="display: block; margin: auto;" /&gt;

---

## Type I &amp; type II errors

&lt;img src="inferential_statistics2_files/tpye_error_table.png" width="700px" height="450px" style="display: block; margin: auto;" /&gt;

---

## Type I &amp; type II errors

&lt;img src="inferential_statistics2_files/meme_error.jpg" width="300px" height="480" style="display: block; margin: auto;" /&gt;

---

## How to make a decision about the .blue[null hypothesis]?

- Calculate the test statistics and compare it to the critical values.

--

.content-box-red[You should always report the test statistics and the alternative hypothesis...]

--

- P-value solves this issue.

.blue[RECALL]

`$$H_0: \: \mu \ge 45 \: \text{against} \: H_1: \: \mu &lt; 45$$`
`$$z = \frac{44-45}{2/\sqrt{365}}=-9.5525$$`

&lt;img src="inferential-statistics2_files/figure-html/unnamed-chunk-40-1.png" width="700px" height="200px" style="display: block; margin: auto;" /&gt;

---

## How to make a decision about the .blue[null hypothesis]?

- In the case of "less" H1, we reject the H0 if the test statistics is **lower or equal** than - 1.65 (`qnorm(.05)`)

--

- It can be seen that in the case of all values satisfying this condition, we get a value smaller than the specified significance level if we substitute in the probability function.

--

- .blue[IDEA:] in the case of "less" alternative, substitute the test statistics into the probability function, and if the resulting value (**p-value**) is lower than the significance level, you can reject the null.


```r
pnorm(-9.5525)
```

```
## [1] 6.330181e-22
```


```r
pnorm(- 1.64)
```

```
## [1] 0.05050258
```


```r
pnorm(- 1.65)
```

```
## [1] 0.04947147
```

---

## How to make a decision about the .blue[null hypothesis]?

For illustrative reasons, let's modify the context again.

.pull-left[
`$$H_0: \: \mu \leq 45 \: \text{against} \: H_1: \: \mu &gt; 45$$`
]

.pull-right[
`$$\bar{x} = 46$$`
]

&lt;img src="inferential-statistics2_files/figure-html/unnamed-chunk-44-1.png" width="700px" height="200px" style="display: block; margin: auto;" /&gt;

--

.pull-left[
`$$z = \frac{46-45}{2/\sqrt{365}}=9.5525$$`
]

.pull-right[

```r
pnorm(9.5525)
```

```
## [1] 1
```
]

---

## How to make a decision about the .blue[null hypothesis]?

For illustrative reasons, let's modify the context again.

.pull-left[
`$$H_0: \: \mu \leq 45 \: \text{against} \: H_1: \: \mu &gt; 45$$`
]

.pull-right[
`$$\bar{x} = 46$$`
]

.pull-left[
`$$z = \frac{46-45}{2/\sqrt{365}}=9.5525$$`
]

.pull-right[

```r
pnorm(9.5525)
```

```
## [1] 1
```
]

- .blue[IDEA:] in the case of "greater" alternative, substitute the test statistics into the probability function, **subtract it from 1**, and if the resulting value (**p-value**) is lower than the significance level, you can reject the null.


```r
1 - pnorm(9.5525)
```

```
## [1] 0
```

---

## How to make a decision about the .blue[null hypothesis]?

For illustrative reasons, let's modify the context again.

.pull-left[
`$$H_0: \: \mu = 45 \: \text{against} \: H_1: \: \mu \neq 45$$`
]

.pull-right[
`$$\bar{x} = 45.2$$`
]

`$$z = \frac{45.2-45}{2/\sqrt{365}}=1.910497$$`

.pull-left[

P-value:


```r
2 * (1 - pnorm(1.910497))
```

```
## [1] 0.05606925
```
]

.pull[
&lt;img src="inferential_statistics2_files/meme_no_accept.jpg" width="300px" height="150px" style="display: block; margin: auto;" /&gt;

]

---

class: inverse, middle, center

## T-test

---

## T-test

- Same theoretical consideration as at the estimation: population variance is unknown (mainly we use this)

- Same steps, but use the `qt` function


```r
qt(.05, df = 365 -1)
```

```
## [1] -1.649051
```

**Critical values are further from the H0 average!**

---

## Code in R


```r
s_length &lt;- iris %&gt;% 
  filter(Species == "setosa") %&gt;% 
  pull(Sepal.Length)
```


```r
t.test(s_length, alternative = "two.sided")
```

```
## 
## 	One Sample t-test
## 
## data:  s_length
## t = 100.42, df = 49, p-value &lt; 2.2e-16
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  4.905824 5.106176
## sample estimates:
## mean of x 
##     5.006
```
---

## Code in R


```r
t.test(s_length, alternative = "greater", mu = 5)
```

```
## 
## 	One Sample t-test
## 
## data:  s_length
## t = 0.12036, df = 49, p-value = 0.4523
## alternative hypothesis: true mean is greater than 5
## 95 percent confidence interval:
##  4.922425      Inf
## sample estimates:
## mean of x 
##     5.006
```

---

class: inverse, middle, center

## Test of Proportion

---

## Test of Proportion

.pull-left[


Proportion in the population:

`$$P = \frac{K}{N}$$`

]

.pull-right[

Estimator:

`$$p = \frac{k}{n}$$`

]

The proportion in a given sample follows binomial distribution.

.pull-left[
`$$\text{Var}(p) = \frac{P(1-P)}{n}$$`
]

.pull-right[
Estimator:
`$$s_p^2 = \frac{p(1-p)}{n-1}$$`

]

In the case of a large sample, due to the CLT, the binomial distribution also approaches the normal distribution, so after determining the standard error, we perform the same steps as in the case of the simple z-test.

---

class: inverse, center, middle

# Two-sample tests

---

## Two-sample test

The idea behind the two-sample mean test (A.K.A. Welch) is to take the difference of sample means and compare them.

`$$t=\frac{\Delta \bar{X}}{s_{\Delta \bar{X}}}=\frac{\bar{X}_1-\bar{X}_2}{\sqrt{s_{\bar{X}_1}^2+s_{\bar{X}_2}^2}}$$`
--

Frequent applications: compare returns of .blue[stocks/indexes/portfolios]

---

## An illustrative example


```r
library(magrittr)

download_yahoo &lt;- . %&gt;% 
  str_remove_all(".+(?&lt;=quote/)|/history?|&amp;frequency=1d") %&gt;% 
  str_replace("filter", "events") %&gt;% 
  str_c("https://query1.finance.yahoo.com/v7/finance/download/", .) %&gt;% 
  read_csv() %&gt;% 
  arrange(desc(Date))

snp_df &lt;- download_yahoo("https://finance.yahoo.com/quote/%5EGSPC/history?period1=-1325635200&amp;period2=1664841600&amp;interval=1d&amp;filter=history&amp;frequency=1d&amp;includeAdjustedClose=true")

nasdaq_df &lt;- download_yahoo("https://finance.yahoo.com/quote/%5EIXIC/history?period1=34560000&amp;period2=1664841600&amp;interval=1d&amp;filter=history&amp;frequency=1d&amp;includeAdjustedClose=true")

snp_df
```

```
## # A tibble: 23,803 × 7
##    Date        Open  High   Low Close `Adj Close`     Volume
##    &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt;
##  1 2022-10-03 3610. 3698. 3605. 3678.       3678. 4806680000
##  2 2022-09-30 3633. 3671. 3584. 3586.       3586. 5645360000
##  3 2022-09-29 3687. 3687. 3610. 3640.       3640. 4681810000
##  4 2022-09-28 3652. 3737. 3641. 3719.       3719. 4684850000
##  5 2022-09-27 3686. 3718. 3623. 3647.       3647. 4577740000
##  6 2022-09-26 3683. 3716. 3645. 3655.       3655. 4886140000
##  7 2022-09-23 3727. 3727. 3647. 3693.       3693. 5144270000
##  8 2022-09-22 3782. 3791. 3749. 3758.       3758. 4284600000
##  9 2022-09-21 3871. 3907. 3789. 3790.       3790. 4078330000
## 10 2022-09-20 3875. 3876. 3828. 3856.       3856. 4058050000
## # … with 23,793 more rows
```

---

## An illustrative example

#### Step 1. Join the two tables

Our goal is to join the two tables by the Date column. For this purpose we should rename the `Adj Close` column to the name of the index. And we are interested only in the days when values for both indexes are available.


```r
inner_join(
  x = select(snp_df, Date, snp = `Adj Close`),
  y = select(nasdaq_df, Date, nasdaq = `Adj Close`),
  by = "Date"
)
```

```
## # A tibble: 13,029 × 3
##    Date         snp nasdaq
##    &lt;date&gt;     &lt;dbl&gt;  &lt;dbl&gt;
##  1 2022-10-03 3678. 10815.
##  2 2022-09-30 3586. 10576.
##  3 2022-09-29 3640. 10738.
##  4 2022-09-28 3719. 11052.
##  5 2022-09-27 3647. 10830.
##  6 2022-09-26 3655. 10803.
##  7 2022-09-23 3693. 10868.
##  8 2022-09-22 3758. 11067.
##  9 2022-09-21 3790. 11220.
## 10 2022-09-20 3856. 11425.
## # … with 13,019 more rows
```

---

#### Step 2. Derive return



```r
stock_index_ret_df &lt;- inner_join(
  x = select(snp_df, Date, snp = `Adj Close`),
  y = select(nasdaq_df, Date, nasdaq = `Adj Close`),
  by = "Date"
) %&gt;% 
  mutate_at(-1, ~ . / lag(.) - 1) %&gt;% # % increase to previous
  drop_na() # no obs in the first row

stock_index_ret_df
```

```
## # A tibble: 13,028 × 3
##    Date            snp   nasdaq
##    &lt;date&gt;        &lt;dbl&gt;    &lt;dbl&gt;
##  1 2022-09-30 -0.0252  -0.0222 
##  2 2022-09-29  0.0153   0.0153 
##  3 2022-09-28  0.0216   0.0293 
##  4 2022-09-27 -0.0193  -0.0201 
##  5 2022-09-26  0.00212 -0.00245
##  6 2022-09-23  0.0104   0.00602
##  7 2022-09-22  0.0175   0.0183 
##  8 2022-09-21  0.00850  0.0139 
##  9 2022-09-20  0.0174   0.0183 
## 10 2022-09-19  0.0114   0.00963
## # … with 13,018 more rows
```

---

## An illustrative example

The `t.test` function works with vectors.


```r
t.test(x = stock_index_ret_df$snp, y = stock_index_ret_df$nasdaq)
```

Identical with tidy solution:


```r
stock_index_ret_df %$% # !!! treat columns as separate vectors
  t.test(snp, nasdaq)
```

```
## 
## 	Welch Two Sample t-test
## 
## data:  snp and nasdaq
## t = 0.4086, df = 25543, p-value = 0.6828
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.0002284549  0.0003487907
## sample estimates:
##     mean of x     mean of y 
## -0.0002189758 -0.0002791437
```



---

# References

&lt;p&gt;&lt;cite&gt;Maddala, G. and K. Lahiri
(2009).
&lt;em&gt;Introduction to Econometrics, 4th Editon&lt;/em&gt;.&lt;/cite&gt;&lt;/p&gt;

---

class: center, middle

# Thank you for your attention!

Slides are available at [www.marcellgranat.com](https://www.marcellgranat.com)
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
